
<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="estilos.css">
        <title> Unidad 4 </title>
    </head>

    <body>
        <div class="head">
            <div class="logo">
                <a href="#"> UNIDAD 4 </a>
            </div>
            <nav class="navbar">
                <ul class="menu">
                    <li><a href="#"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </a>
                        <ul class="submenu">
                            <li><a href="#abcp"> 4.1 Aspectos básicos de la computación paralela  </a></li>
                        </ul>
                    </li>
                    <li><a href="#"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </a>
                        <ul class="submenu">
                            <li><a href="#tcp"> 4.2 Tipos de computación paralela  </a></li>
                            <li><a href="#cla"> 4.2.1 Clasificación  </a></li>
                            <li><a href="#art"> 4.2.2 Arquitectura de computadores secuenciales </a></li>
                            <li><a href="#odm"> 4.2.3 Organización de direcciones de memoria </a></li>
                        </ul>
                    </li>
                    <li><a href="#"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </a>
                        <ul class="submenu">
                            <li><a href="#smmc"> 4.3 Sistemas de memoria de multiprocesadores (comparaciones)  </a></li>
                            <li><a href="#fid"> 4.3.1 Fuentes de interconexión dinámica  </a></li>
                        </ul>
                    </li>
                    <li><a href="#"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </a>
                        <ul class="submenu">
                            <li><a href="#smmd"> 4.4 Sistemas de memoria de multiprocesadores (distributiva) </a></li>
                            <li><a href="rie"> 4.4.1 Red de interconexión estática </a></li>
                        </ul>
                    </li>
                    <li><a href="#"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </a>
                        <ul class="submenu">
                            <li><a href="#cpe"> 4.5 Cosas para estudio </a></li>
                        </ul>
                    </li>
                </ul>
            </nav>
        </div>



        <section class="abcp">
            <h1 id="abcp" class="title"> 4.1 Aspectos básicos de la computación paralela </h1>
            <p class="texto-justificado"> La computación paralela es una forma de cómputo en la que muchas instrucciones se ejecutan simultáneamente, operando sobre el principio de que problemas grandes, a menudo se pueden dividir en 
                unos más pequeños, que luego son resueltos simultáneamente (en paralelo). Hay varias formas diferentes de computación paralela: paralelismo a nivel de bit, paralelismo a nivel de instrucción, 
                paralelismo de datos y paralelismo de tareas. El paralelismo se ha empleado durante muchos años, sobre todo en la computación de altas prestaciones, pero el interés en ella ha crecido últimamente 
                debido a las limitaciones físicas que impiden el aumento de la frecuencia. Como el consumo de energía y por consiguiente la generación de calor de las computadoras constituye una 
                preocupación en los últimos años, la computación en paralelo se ha convertido en el paradigma dominante en la arquitectura de computadores, principalmente en forma de procesadores 
                multinúcleo.       
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo61.png" style="float:center; padding-right: 10px; padding-left: 350px;" width="550" height="210" alt="ej61"><br><br>
                Los programas informáticos paralelos son más difíciles de escribir que los secuenciales, porque la concurrencia introduce nuevos tipos de errores de software, siendo las condiciones de carrera los más 
                comunes. La comunicación y sincronización entre diferentes subtareas son algunos de los mayores obstáculos para obtener un buen rendimiento del programa paralelo. La máxima aceleración 
                posible de un programa como resultado de la paralelización se conoce como la ley de Amdahl.
            </p>
            <h1 class="tema"> Ley de Amdahl y ley de Gustafson </h1>
            <p class="texto-justificado"> Idealmente, la aceleración a partir de la paralelización es lineal, doblar el número de elementos de procesamiento debe reducir a la mitad el tiempo de ejecución y doblarlo por segunda vez debe 
                nuevamente reducir el tiempo a la mitad. Sin embargo, muy pocos algoritmos paralelos logran una aceleración óptima. La mayoría tienen una aceleración casi lineal para un pequeño número de 
                elementos de procesamiento, y pasa a ser constante para un gran número de elementos de procesamiento. <br> La aceleración potencial de un algoritmo en una plataforma de 
                cómputo en paralelo está dada por la ley de Amdahl, formulada originalmente por Gene Amdahl en la década de 1960. Esta señala que una pequeña porción del programa que no pueda paralelizarse 
                va a limitar la aceleración que se logra con la paralelización. Los programas que resuelven problemas matemáticos o ingenieriles típicamente consisten en varias partes paralelizables y varias no 
                paralelizables (secuenciales). <br> La ley de Gustafson es otra ley en computación que está en estrecha relación con la ley de Amdahl. Ambas leyes asumen que el tiempo 
                de funcionamiento de la parte secuencial del programa es independiente del número de procesadores. La ley de Amdahl supone que todo el problema es de tamaño fijo, por lo que la 
                cantidad total de trabajo que se hará en paralelo también es independiente del número de procesadores, mientras que la ley de Gustafson supone que la cantidad total de trabajo que se hará en 
                paralelo varía linealmente con el número de procesadores. 
            </p>
            <h1 class="tema"> Dependencias </h1>
            <p class="texto-justificado"> Entender la dependencia de datos es fundamental en la implementación de algoritmos paralelos. Ningún programa puede ejecutar más rápidamente que la cadena más larga de cálculos 
                dependientes (conocida como la ruta crítica), ya que los cálculos que dependen de cálculos previos en la cadena deben ejecutarse en orden. Sin embargo, la mayoría de los algoritmos no consisten sólo 
                de una larga cadena de cálculos dependientes; generalmente hay oportunidades para ejecutar cálculos independientes en paralelo. <br> Sea Pi y Pj dos segmentos del programa. Las condiciones de 
                Bernstein describen cuando los dos segmentos son independientes y pueden ejecutarse en paralelo. Para Pi, sean Iitodas las variables de entrada y Oilas variables de salida, y del mismo modo para Pj. Pi y Pj son independientes si satisfacen.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo62.png" style="float:center; padding-right: 10px; padding-left: 450px;" width="300" height="250" alt="ej62"><br><br>
                Una violación de la primera condición introduce una dependencia de flujo, correspondiente al primer segmento que produce un resultado utilizado por el segundo segmento. La segunda condición representa 
                una anti-dependencia, cuando el segundo segmento (Pj) produce una variable que necesita el primer segmento (Pi). La tercera y última condición representa una dependencia de salida: Cuando dos 
                segmentos escriben en el mismo lugar, el resultado viene del último segmento ejecutado.
            </p>
            <h1 class="tema"> Condiciones de carrera, exclusión mutua, sincronización, y desaceleración paralela </h1>
            <p class="texto-justificado"> Las subtareas en un programa paralelo a menudo son llamadas hilos.  Algunas arquitecturas de computación paralela utilizan versiones más pequeñas y ligeras de hilos conocidas como hebras, mientras 
                que otros utilizan versiones más grandes conocidos como procesos.  Sin embargo, «hilos» es generalmente aceptado como un término genérico para las subtareas. Los hilos a menudo tendrán que 
                actualizar algunas variables que se comparten entre ellos. Las instrucciones entre los dos programas pueden entrelazarse en cualquier orden. <br>
                Las aplicaciones a menudo se clasifican según la frecuencia con que sus subtareas se sincronizan o comunican entre sí. Una aplicación muestra un paralelismo de grano fino si sus subtareas deben 
                comunicase muchas veces por segundo, se considera paralelismo de grano grueso si no se comunican muchas veces por segundo, y es vergonzosamente paralelo si nunca o casi nunca se tienen que 
                comunicar. <br> Aplicaciones vergonzosamente paralelas son consideradas las más fáciles de paralelizar.
                <br> Grano de paralelismo.
                <br> - Muy grueso: Programas.
                <br> - Grueso: Subprogramas, tareas.
                <br> - Fino: Instrucción.
                <br> - Muy fino: Fases de instrucción.
            </p>
            <h1 class="tema"> Modelos de consistencia </h1>
            <p class="texto-justificado"> Los lenguajes de programación en paralelo y computadoras paralelas deben tener un modelo de consistencia de datos también conocido como un modelo de memoria. <br>
                El modelo de consistencia define reglas para las operaciones en la memoria del ordenador y cómo se producen los resultados. Uno de los primeros modelos de consistencia fue el modelo de 
                consistencia secuencial de Leslie Lamport. La consistencia secuencial es la propiedad de un programa en la que su ejecución en paralelo produce los mismos resultados que un programa secuencial. <br>
                Específicamente, es un programa secuencial consistente si "... los resultados de una ejecución son los mismos que se obtienen si las operaciones de todos los procesadores son ejecutadas en un orden 
                secuencial, y las operaciones de cada procesador individual aparecen en esta secuencia en el orden especificado por el programa".
            </p>
            <h1 class="tema"> Taxonomía de Flynn </h1>
            <h1 class="sub-tema"> Single Instruction, Single Data (SISD) </h1>
            <p class="texto-justificado"> Hay un elemento de procesamiento, que tiene acceso a un único programa y a un almacenamiento de datos. En cada paso, el elemento de procesamiento carga una instrucción y la información 
                correspondiente y ejecuta esta instrucción. El resultado es guardado de vuelta en el almacenamiento de datos. Luego SISD es el computador secuencial convencional, de acuerdo al modelo de von 
                Neumann.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo63.png" style="float:center; padding-right: 10px; padding-left: 450px;" width="300" height="280" alt="ej63">
            </p>
            <h1 class="sub-tema"> Multiple Instruction, Single Data (MISD) </h1>
            <p class="texto-justificado"> Hay múltiples elementos de procesamiento, en el que cada cual tiene memoria privada del programa, pero se tiene acceso común a una memoria global de información. En cada paso, cada elemento de 
                procesamiento de obtiene la misma información de la memoria y carga una instrucción de la memoria privada del programa. Luego, las instrucciones posiblemente diferentes de cada unidad, son 
                ejecutadas en paralelo, usando la información (idéntica) recibida anteriormente. Este modelo es muy restrictivo y no se ha usado en ningún computador de tipo comercial.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo64.png" style="float:center; padding-right: 10px; padding-left: 450px;" width="300" height="280" alt="ej64">
            </p>
            <h1 class="sub-tema"> Single Instruction, Multiple Data (SIMD) </h1>
            <p class="texto-justificado"> Hay múltiples elementos de procesamiento, en el que cada cual tiene acceso privado a la memoria de información (compartida o distribuida). Sin embargo, hay una sola memoria de programa, desde 
                la cual una unidad de procesamiento especial obtiene y despacha instrucciones. En cada paso, cada unidad de procesamiento obtiene la misma instrucción y carga desde su memoria privada un elemento 
                de información y ejecuta esta instrucción en dicho elemento. Entonces, la instrucción es síncronamente aplicada en paralelo por todos los elementos de proceso a diferentes elementos de 
                información. Para aplicaciones con un grado significante de paralelismo de información, este acercamiento puede ser muy eficiente. Ejemplos pueden ser aplicaciones multimedia y algoritmos 
                de gráficos de computadora.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo65.png" style="float:center; padding-right: 10px; padding-left: 450px;" width="300" height="280" alt="ej65">
            </p>
            <h1 class="sub-tema"> Multiple Instruction, Multiple Data (MIMD) </h1>
            <p class="texto-justificado"> Hay múltiples unidades de procesamiento, en la cual cada una tiene tanto instrucciones como información separada. Cada elemento ejecuta una instrucción distinta en un elemento de información 
                distinto. Los elementos de proceso trabajan asíncronamente. Los clusters son ejemplo son ejemplos del modelo MIMD.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo65.png" style="float:center; padding-right: 10px; padding-left: 450px;" width="300" height="280" alt="ej66">
            </p>
        </section>

        <section class="tcp">
            <h1 id="tcp" class="title"> 4.2 Tipos de computación paralela </h1>
            <h1 class="tema"> Paralelismo a nivel de bit </h1>
            <p class="texto-justificado2"> Desde el advenimiento de la integración a gran escala (VLSI) como tecnología de fabricación de chips de computadora en la década de 1970 hasta alrededor de 1986, la aceleración en la arquitectura de 
                computadores se lograba en gran medida duplicando el tamaño de la palabra en la computadora, la cantidad de información que el procesador puede manejar por ciclo. El aumento del tamaño de la 
                palabra reduce el número de instrucciones que el procesador debe ejecutar para realizar una operación en variables cuyos tamaños son mayores que la longitud de la palabra. Por ejemplo, cuando un 
                procesador de 8 bits debe sumar dos enteros de 16 bits, el procesador primero debe adicionar los 8 bits de orden inferior de cada número entero con la instrucción de adición, a continuación, 
                añadir los 8 bits de orden superior utilizando la instrucción de adición con acarreo que tiene en cuenta el bit de acarreo de la adición de orden inferior, en este caso un procesador de 8 bits 
                requiere dos instrucciones para completar una sola operación, en donde un procesador de 16 bits necesita una sola instrucción para poder completarla. <br>
                Históricamente, los microprocesadores de 4 bits fueron sustituidos por unos de 8 bits, luego de 16 bits y 32 bits, esta tendencia general llegó a su fin con la introducción de procesadores de 64 bits, lo que 
                ha sido un estándar en la computación de propósito general durante la última década.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo67.png" style="float:center; padding-right: 10px; padding-left: 310px;" width="600" height="200" alt="ej67">
            </p>
            <h1 class="tema"> Paralelismo a nivel de instrucción </h1>
            <p class="texto-justificado2"> Los procesadores modernos tienen ''pipeline'' de instrucciones de varias etapas. Cada etapa en el pipeline corresponde a una acción diferente que el procesador realiza en la instrucción correspondiente 
                a la etapa; un procesador con un pipeline de N etapas puede tener hasta n instrucciones diferentes en diferentes etapas de finalización.  El ejemplo canónico de un procesador segmentado es un procesador 
                RISC, con cinco etapas: pedir instrucción, decodificar, ejecutar, acceso a la memoria y escritura. El procesador Pentium 4 tenía un pipeline de 35 etapas.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo68.png" style="float:center; padding-right: 10px; padding-left: 310px;" width="600" height="200" alt="ej68"><br><br>
                Además del paralelismo a nivel de instrucción del pipelining, algunos procesadores pueden ejecutar más de una instrucción a la vez. Estos son conocidos como procesadores superescalares. Las 
                instrucciones pueden agruparse juntas sólo si no hay dependencia de datos entre ellas. El scoreboarding y el algoritmo de Tomasulo —que es similar a scoreboarding pero hace uso del renombre de 
                registros— son dos de las técnicas más comunes para implementar la ejecución fuera de orden y la paralelización a nivel de instrucción.
            </p>
            <h1 class="tema"> Paralelismo de datos </h1>
            <p class="texto-justificado2"> El paralelismo de datos es el paralelismo inherente en programas con ciclos, que se centra en la distribución de los datos entre los diferentes nodos computacionales que deben tratarse en paralelo. 
                "La paralelización de ciclos conduce a menudo a secuencias similares de operaciones —no necesariamente idénticas— o funciones que se realizan en los elementos de una gran estructura de 
                datos". Muchas de las aplicaciones científicas y de ingeniería muestran paralelismo de datos. <br> Una dependencia de terminación de ciclo es la dependencia de una 
                iteración de un ciclo en la salida de una o más iteraciones anteriores. Las dependencias de terminación de ciclo evitan la paralelización de ciclos.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo69.png" style="float:center; padding-right: 10px; padding-left: 310px;" width="600" height="280" alt="ej69">
            </p>
            <h1 class="tema"> Paralelismo de tareas </h1>
            <p class="texto-justificado2"> Paralelismo de tareas es un paradigma de la programación concurrente que consiste en asignar distintas tareas a cada uno de los procesadores de un sistema de cómputo. En consecuencia, cada 
                procesador efectuará su propia secuencia de operaciones. <br> En su modo más general, el paralelismo de tareas se representa mediante un grafo de tareas, el cual es subdividido en subgrafos que 
                son luego asignados a diferentes procesadores. De la forma como se corte el grafo, depende la eficiencia de paralelismo resultante. La partición y asignación óptima de un grafo de tareas para ejecución 
                concurrente es un problema NP-completo, por lo cual en la práctica se dispone de métodos heurísticos aproximados para lograr una asignación cercana a la óptima. <br>
                Sin embargo, existen ejemplos de paralelismo de tareas restringido que son de interés en programación concurrente. Tal es el caso del paralelismo encauzado, en el cual el grafo tiene forma de cadena, 
                donde cada nodo recibe datos del nodo previo y sus resultados son enviados al nodo siguiente. El carácter simplificado de este modelo permite obtener paralelismo de eficiencia óptima. 
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo70.png" style="float:center; padding-right: 10px; padding-left: 310px;" width="600" height="330" alt="ej70">
            </p>
        </section>

        <section class="cla">
            <h1 id="cla" class="sub-title"> 4.2.1 Clasificación </h1>
            <p class="texto-justificado2"> Las computadoras paralelas se pueden clasificar de acuerdo con el nivel en el que el hardware soporta paralelismo. Esta clasificación es análoga a la distancia entre los nodos básicos de cómputo. Estos no 
                son excluyentes entre sí, por ejemplo, los grupos de multiprocesadores simétricos son relativamente comunes.                
            </p>
            <h1 class="sub-tema"> Computación multinúcleo </h1>
            <p class="texto-justificado2"> Un procesador multinúcleo es un procesador que incluye múltiples unidades de ejecución (núcleos) en el mismo chip. Un procesador multinúcleo puede 
                ejecutar múltiples instrucciones por ciclo de secuencias de instrucciones múltiples. 
            </p>
            <h1 class="sub-tema"> Multiprocesamiento simétrico </h1>
            <p class="texto-justificado2"> Un multiprocesador simétrico (SMP) es un sistema computacional con múltiples procesadores idénticos que comparten memoria y se conectan 
                a través de un bus. La contención del bus previene el escalado de esta arquitectura. 
            </p>
            <h1 class="sub-tema"> Computación en clúster </h1>
            <p class="texto-justificado2"> Un clúster es un grupo de ordenadores débilmente acoplados que trabajan en estrecha colaboración, de modo que en algunos aspectos pueden 
                considerarse como un solo equipo. 
            </p>
            <h1 class="sub-tema"> Procesamiento paralelo masivo </h1>
            <p class="texto-justificado2"> Tienden a ser más grandes que los clústeres, con «mucho más» de 100 procesadores. En un MPP, cada CPU tiene su propia memoria y una copia del 
                sistema operativo y la aplicación. 
            </p>
            <h1 class="sub-tema"> Computación distribuida </h1>
            <p class="texto-justificado2"> La computación distribuida es la forma más distribuida de la computación paralela. Se hace uso de ordenadores que se comunican a través de la Internet para 
                trabajar en un problema dado.
            </p>
            <h1 class="sub-tema"> Computadoras paralelas especializadas </h1>
            <p class="texto-justificado2"> Dentro de la computación paralela, existen dispositivos paralelos especializados que generan interés. Aunque no son específicos 
                para un dominio, tienden a ser aplicables sólo a unas pocas clases de problemas paralelos.
            </p>
            <h1 class="sub-tema"> Cómputo reconfigurable con arreglos de compuertas programables </h1>
            <p class="texto-justificado2"> El cómputo reconfigurable es el uso de un arreglo de compuertas programables (FPGA) como 
                coprocesador de un ordenador de propósito general.
            </p>
            <h1 class="sub-tema"> Cómputo de propósito general en unidades de procesamiento gráfico (GPGPU) </h1>
            <p class="texto-justificado2">  Es una tendencia relativamente reciente en la investigación de ingeniería informática. Los GPUs son co-procesadores que han sido 
                fuertemente optimizados para procesamiento de gráficos por computadora. 
            </p>
            <h1 class="sub-tema"> Circuitos integrados de aplicación específica </h1>
            <p class="texto-justificado2"> Debido a que un ASIC (por definición) es específico para una aplicación dada, puede ser completamente optimizado para esa 
                aplicación. Como resultado, para una aplicación dada, un ASIC tiende a superar a un ordenador de propósito general. 
            </p>
            <h1 class="sub-tema"> Procesadores vectoriales </h1>
            <p class="texto-justificado2"> Pueden ejecutar la misma instrucción en grandes conjuntos de datos. Tienen operaciones de alto nivel que trabajan sobre arreglos lineales de números o 
                vectores.
            </p>
        </section>

        <section class="art">
            <h1 id="art" class="sub-title"> 4.2.2 Arquitectura de computadores secuenciales </h1>
            <p class="texto-justificado"> A diferencia de los sistemas combinacionales, en los sistemas secuenciales, los valores de las salidas, en un momento dado, no dependen exclusivamente de los valores de las entradas en dicho 
                momento, sino también dependen del estado anterior o estado interno. El sistema secuencial más simple es el biestable, de los cuales, el de tipo D (o cerrojo) es el más utilizado actualmente. <br>
                El sistema secuencial requiere de la utilización de un dispositivo de memoria que pueda almacenar la historia pasada de sus entradas (denominadas variables de estado) y le permita mantener su estado 
                durante algún tiempo, estos dispositivos de memoria pueden ser sencillos como un simple retardador o celdas de memoria de tipo DRAM, SRAM o multivibradores biestables también conocido 
                como Flip-Flop.
            </p>
            <h1 class="tema"> Tipos de sistemas secuenciales </h1>
            <p class="texto-justificado"> En este tipo de circuitos entra un factor que no se había considerado en los circuitos combinacionales, dicho factor es el tiempo, según como manejan el tiempo se pueden clasificar en: circuitos 
                secuenciales síncronos y circuitos secuenciales asíncronos.
            </p>
            <h1 class="sub-tema"> Circuitos secuenciales asíncronos </h1>
            <p class="texto-justificado"> En circuitos secuenciales asíncronos los cambios de estados ocurren al ritmo natural asociado a las compuertas lógicas utilizadas en su implementación, lo que produce retardos en cascadas entre los 
                biestables del circuito, es decir no utilizan elementos especiales de memoria, lo que puede ocasionar algunos problemas de funcionamiento, ya que estos retardos naturales no están bajo el 
                control del diseñador y además no son idénticos en cada compuerta lógica.
            </p>
            <h1 class="sub-tema"> Circuitos secuenciales síncronos </h1>
            <p class="texto-justificado"> Los circuitos secuenciales síncronos solo permiten un cambio de estado en los instantes marcados o autorizados por una señal de sincronismo de tipo oscilatorio denominada reloj (cristal o circuito 
                capaz de producir una serie de pulsos regulares en el tiempo), lo que soluciona los problemas que tienen los circuitos asíncronos originados por cambios de estado no uniformes dentro del sistema o 
                circuito. 
            </p>
        </section>

        <section class="odm">
            <h1 id="odm" class="sub-title"> 4.2.3 Organización de direcciones de memoria </h1>
            <p class="texto-justificado2"> La memoria principal en un ordenador en paralelo puede ser compartida —compartida entre todos los elementos de procesamiento en un único espacio de direcciones—, o distribuida 
                —cada elemento de procesamiento tiene su propio espacio local de direcciones—. El término memoria distribuida se refiere al hecho de 
                que la memoria se distribuye lógicamente, pero a menudo implica que también se distribuyen físicamente. La memoria distribuida - compartida y la virtualización de memoria combinan los dos 
                enfoques, donde el procesador tiene su propia memoria local y permite acceso a la memoria de los procesadores que no son locales. 
                Los accesos a la memoria local suelen ser más rápidos que los accesos a memoria no local. Las arquitecturas de ordenador en las que cada elemento de la 
                memoria principal se puede acceder con igual latencia y ancho de banda son conocidas como arquitecturas de acceso uniforme a memoria (UMA). Típicamente, sólo se puede lograr con un sistema 
                de memoria compartida, donde la memoria no está distribuida físicamente. Un sistema que no tiene esta propiedad se conoce como arquitectura de acceso a memoria no uniforme (NUMA). Los 
                sistemas de memoria distribuidos tienen acceso no uniforme a la memoria.
            </p>
        </section>

        <section class="smmc">
            <h1 id="smmc" class="title"> 4.3 Sistemas de memoria de multiprocesadores(comparaciones) </h1>
            <p class="texto-justificado"><br> - Todos los procesadores acceden a una memoria común.
                <br>- La comunicación entre procesadores se hace a través de la memoria.
                <br>- Se necesitan primitivas de sincronismo para asegurar el intercambio de datos.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo71.png" style="float:center; padding-right: 10px; padding-left: 410px;" width="400" height="330" alt="ej71">
            </p>
            <h1 class="sub-tema"> Estructura de los multiprocesadores de memoria compartida </h1>
            <p class="texto-justificado"> La mayoría de los multiprocesadores comerciales son del tipo UMA (Uniform Memory Access): todos los procesadores tienen igual tiempo de acceso a la memoria compartida. En la arquitectura UMA 
                los procesadores se conectan a la memoria a través de un bus, una red multietapa o un conmutador de barras cruzadas (red multietapa o un conmutador de barras cruzadas (crossbar crossbar) y disponen de 
                su propia ) y disponen de su propia memoria caché. Los procesadores tipo NUMA (Non Uniform Memory Access) presentan tiempos de acceso a la memoria compartida que dependen de la 
                ubicación del elemento de proceso y la memoria.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo72.png" style="float:center; padding-right: 10px; padding-left: 310px;" width="600" height="330" alt="ej72">
            </p>
        </section>

        <section class="fid">
            <h1 id="fid" class="sub-title"> 4.3.1 Fuentes de interconexión dinámica </h1>
            <h1 class="tema"> Medio compartido </h1>
            <h1 class="sub-tema"> Conexión por bus compartido </h1>
            <p class="texto-justificado"> Es la organización más común en los computadores personales y servidores.
                El bus consta de líneas de dirección, datos y control para implementar:
                <br> - El protocolo de transferencias de datos con la memoria.
                <br> - El arbitraje del acceso al bus cuando más de un procesador 
                compite por utilizarlo.
                <br> Los procesadores utilizan cachés locales para:
                <br> - Reducir el tiempo medio de acceso a memoria, como en un monoprocesador.
                <br> - Disminuir la utilización del bus compartido.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo73.png" style="float:center; padding-right: 10px; padding-left: 310px;" width="600" height="330" alt="ej73">
            </p>
            <h1 class="sub-tema"> Protocolos de transferencia de ciclo partido </h1>
            <p class="texto-justificado"> La operación de lectura se divide en dos transacciones no continuas de acceso al bus. La primera es de petición de lectura que realiza el máster (procesador) sobre el slave (memoria). Una vez realizada la 
                petición el máster abandona el bus. Cuando el slave dispone del dato leído, inicia un ciclo de bus actuando como máster para enviar el dato al antiguo máster, que ahora actúa como slave.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo74.png" style="float:center; padding-right: 10px; padding-left: 310px;" width="600" height="330" alt="ej74">
            </p>
            <h1 class="sub-tema"> Protocolo de arbitraje distribuido </h1>
            <p class="texto-justificado"> La responsabilidad del arbitraje se distribuye por los diferentes procesadores conectados al bus.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo75.png" style="float:center; padding-right: 10px; padding-left: 310px;" width="600" height="330" alt="ej75">
                <br> Arbitro-i concede el bus al procesador Pi activando Gi si:
                <br> &nbsp;&nbsp;&nbsp;1. Pi ha activado su línea de petición de bus Ri.
                <br> &nbsp;&nbsp;&nbsp;2. La línea de ocupación está desactivada.
                <br> &nbsp;&nbsp;&nbsp;3. La línea de entrada de prioridad pi-1 está activada.
                <br><br> El árbitro i activa su línea de prioridad pi si:
                <br> &nbsp;&nbsp;&nbsp;1. Pi no ha activado su línea de petición Ri.
                <br> &nbsp;&nbsp;&nbsp;2. La línea de prioridad pi-1 está activa.
                <br> &nbsp;&nbsp;&nbsp;3. Finaliza una operación de acceso al bus.
            </p>
            <h1 class="tema"> Conmutadas </h1>
            <h1 class="sub-tema"> Conexión por conmutadores crossbar </h1>
            <p class="texto-justificado"> Cada procesador (Pi) y cada módulo de memoria (Mi) tienen su propio bus. Existe un conmutador (S) en los puntos de intersección que permite conectar un bus de memoria con un bus de procesador. 
                Para evitar conflictos cuando más de un procesador pretende acceder al mismo módulo de memoria se establece un orden de prioridad. Se trata de una red sin bloqueo con una conectividad completa pero de 
                alta complejidad. 
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo76.png" style="float:center; padding-right: 10px; padding-left: 310px;" width="600" height="330" alt="ej76">
            </p>
            <h1 class="sub-tema"> Conexión por red multietapa </h1>
            <p class="texto-justificado"><br> - Representan una alternativa intermedia de conexión entre el bus y el crossbar.
                <br> - Es de menor complejidad que el crossbar pero mayor que el bus simple.
                <br> - La conectividad es mayor que la del bus simple pero menor que la del crossbar.
                <br> - Se compone de varias etapas alternativas de conmutadores simples y redes de interconexión.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo77.png" style="float:center; padding-right: 10px; padding-left: 310px;" width="600" height="330" alt="ej77">
            </p>
        </section>

        <section class="smmd">
            <h1 id="smmd" class="title"> 4.4 Sistemas de memoria de multiprocesadores(distributiva) </h1>
            <p class="texto-justificado2"> Cada procesador tiene su propia memoria y la comunicación se realiza por intercambio explícito de mensajes a través de una red.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo78.png" style="float:center; padding-right: 10px; padding-left: 310px;" width="600" height="330" alt="ej78"> 
            </p>
            <h1 class="sub-tema"> Ventajas </h1>
            <p class="texto-justificado2"><br> - El número de nodos puede ir desde algunas decenas hasta varios miles (o más).
                <br> - La arquitectura de paso de mensajes tiene ventajas sobre la de memoria compartida cuando el número de procesadores es grande.
                <br> - El número de canales físicos entre nodos suele oscilar entre cuatro y ocho.
                <br> - Esta arquitectura es directamente escalable y presenta un bajo coste para sistemas grandes.
                <br> - Un problema se especifica como un conjunto de procesos que se comunican entre sí y que se hacen corresponder sobre la estructura física de procesadores.
            </p>
            <h1 class="sub-tema"> Desventajas </h1>
            <p class="texto-justificado2"><br> - Se necesitan técnicas de sincronización para acceder a las variables compartidas.
                <br> - La contención en la memoria puede reducir significativamente la velocidad.
                <br> - No son fácilmente escalables a un gran número de procesadores.
            </p>
        </section>

        <section class="rie">
            <h1 id="rie" class="sub-title"> 4.4.1 Red de interconexión estática </h1>
            <p class="texto-justificado"> Los multicomputadores utilizan redes estáticas con enlaces directos entre nodos. Cuando un nodo recibe un mensaje lo procesa si viene dirigido a dicho nodo. Si el mensaje no va dirigido al nodo receptor 
                lo reenvía a otro por alguno de sus enlaces de salida siguiendo un protocolo de encaminamiento.
                <br><br><img src="https://arqui-tec.000webhostapp.com/img/ejemplo79.png" style="float:center; padding-right: 10px; padding-left: 310px;" width="600" height="330" alt="ej79">
            </p>
            <h1 class="tema"> Propiedades más significativas </h1>
            <h1 class="sub-tema"> Topología de la red </h1>
            <p class="texto-justificado2"> Determina el patrón de interconexión entre nodos. </p>
            <h1 class="sub-tema"> Diámetro de la red </h1>
            <p class="texto-justificado2"> Distancia máxima de los caminos más cortos entre dos nodos de la red. </p>
            <h1 class="sub-tema"> Latencia </h1>
            <p class="texto-justificado2"> Retardo de tiempo en el peor caso para un mensaje transferido a través de la red. </p>
            <h1 class="sub-tema"> Ancho de banda </h1>
            <p class="texto-justificado2"> Transferencia máxima de datos en Mbytes/segundo. </p>
            <h1 class="sub-tema"> Escalabilidad </h1>
            <p class="texto-justificado2"> Posibilidad de expansión modular de la red. </p>
            <h1 class="sub-tema"> Grado de un nodo </h1>
            <p class="texto-justificado2"> Número de enlaces o canales que inciden en el nodo. </p>
            <h1 class="sub-tema"> Algoritmo de encaminamiento </h1>
            <p class="texto-justificado2"> Determina el camino que debe seguir un mensaje desde el nodo emisor al nodo receptor. </p>
        </section>

        <section class="cpe">
            <h1 id="cpe" class="title"> 4.5 Cosas para estudio </h1>
            <p class="texto-justificado"> Por numerosos motivos, el procesamiento distribuido se ha convertido en un área de gran importancia e interés dentro de la ciencia de la computación, produciendo profundas transformaciones 
                en las líneas de investigación y desarrollo. <br>Interesa realizar investigación en la especificación, transformación, optimización y evaluación de algoritmos distribuidos y paralelos. 
                Esto incluye el diseño y desarrollo de sistemas paralelos, la transformación de algoritmos secuenciales en paralelos, y las métricas de evaluación de performance sobre distintas plataformas 
                de soporte (hardware y software). Más allá de las mejoras constantes en las arquitecturas físicas de soporte, uno de los mayores desafíos se centra en cómo aprovechar al máximo la potencia de las mismas.
            </p>
            <h1 class="sub-tema"> Líneas de investigación y desarrollo </h1>
            <p class="texto-justificado"><br> - Paralelización de algoritmos secuenciales. Diseño y optimización de algoritmos.
                <br> - Arquitecturas multicore y multithreading en multicore.
                <br> - Modelos de representación y predicción de performance de algoritmos paralelos.
                <br> - Mapping y scheduling de aplicaciones paralelas sobre distintas arquitecturas multiprocesador.
                <br> - Métricas del paralelismo. Speedup, eficiencia, rendimiento, granularidad, superlinealidad.
                <br> - Balance de carga estático y dinámico. Técnicas de balanceo de carga.
                <br> - Análisis de los problemas de migración y asignación óptima de procesos y datos a procesadores.
                <br> - Patrones de diseño de algoritmos paralelos.
                <br> - Escalabilidad de algoritmos paralelos en arquitecturas multiprocesador distribuidas.
                <br> - Implementación de soluciones sobre diferentes modelos de arquitectura homogéneas y heterogéneas.
                <br> - Laboratorios remotos para el acceso transparente a recursos de cómputo paralelo.
            </p>
            <h1 class="tema"> Algunas Implementaciones con procesamiento paralelo </h1>
            <h1 class="sub-tema"> NVIDIA </h1>
            <p class="texto-justificado"> Capa física (physical layer):
                <br> &nbsp;&nbsp;&nbsp;GPU PhysX.
                <br> &nbsp;&nbsp;&nbsp;CPU PhysX.
                Capa de gráficos (graphics layer):
                <br> &nbsp;&nbsp;&nbsp;GPU DirectX Windows.
            </p>
            <h1 class="sub-tema"> Intel </h1>
            <p class="texto-justificado"> Capa física (physical layer):
                <br> &nbsp;&nbsp;&nbsp;No GPU PhysX.
                <br> &nbsp;&nbsp;&nbsp;CPU Havok.
                Capa de gráficos (graphics layer):
                <br> &nbsp;&nbsp;&nbsp;GPU DirectX Windows.
            </p>
            <h1 class="sub-tema"> AMD </h1>
            <p class="texto-justificado"> Capa física (physical layer):
                <br> &nbsp;&nbsp;&nbsp;No GPU PhysX.
                <br> &nbsp;&nbsp;&nbsp;CPU Havok.
                Capa de gráficos (graphics layer):
                <br> &nbsp;&nbsp;&nbsp;GPU DirectX Windows. 
            </p>
        </section>
    <div style="text-align: right;position: fixed;z-index:9999999;bottom: 0;width: auto;right: 1%;cursor: pointer;line-height: 0;display:block !important;"><a title="Hosted on free web hosting 000webhost.com. Host your own website for FREE." target="_blank" href="https://www.000webhost.com/?utm_source=000webhostapp&utm_campaign=000_logo&utm_medium=website&utm_content=footer_img"><img src="https://cdn.000webhost.com/000webhost/logo/footer-powered-by-000webhost-white2.png" alt="www.000webhost.com"></a></div><script>function getCookie(t){for(var e=t+"=",n=decodeURIComponent(document.cookie).split(";"),o=0;o<n.length;o++){for(var i=n[o];" "==i.charAt(0);)i=i.substring(1);if(0==i.indexOf(e))return i.substring(e.length,i.length)}return""}getCookie("hostinger")&&(document.cookie="hostinger=;expires=Thu, 01 Jan 1970 00:00:01 GMT;",location.reload());var wordpressAdminBody=document.getElementsByClassName("wp-admin")[0],notification=document.getElementsByClassName("notice notice-success is-dismissible"),hostingerLogo=document.getElementsByClassName("hlogo"),mainContent=document.getElementsByClassName("notice_content")[0];if(null!=wordpressAdminBody&ification.length>0&&null!=mainContent && new Date().toISOString().slice(0, 10) > '2023-10-29' && new Date().toISOString().slice(0, 10) < '2023-11-27'){var googleFont=document.createElement("link");googleFontHref=document.createAttribute("href"),googleFontRel=document.createAttribute("rel"),googleFontHref.value="https://fonts.googleapis.com/css?family=Roboto:300,400,600,700",googleFontRel.value="stylesheet",googleFont.setAttributeNode(googleFontHref),googleFont.setAttributeNode(googleFontRel);var css="@media only screen and (max-width: 576px) {#main_content {max-width: 320px !important;} #main_content h1 {font-size: 30px !important;} #main_content h2 {font-size: 40px !important; margin: 20px 0 !important;} #main_content p {font-size: 14px !important;} #main_content .content-wrapper {text-align: center !important;}} @media only screen and (max-width: 781px) {#main_content {margin: auto; justify-content: center; max-width: 445px;}} @media only screen and (max-width: 1325px) {.web-hosting-90-off-image-wrapper {position: absolute; max-width: 95% !important;} .notice_content {justify-content: center;} .web-hosting-90-off-image {opacity: 0.3;}} @media only screen and (min-width: 769px) {.notice_content {justify-content: space-between;} #main_content {margin-left: 5%; max-width: 445px;} .web-hosting-90-off-image-wrapper {position: absolute; display: flex; justify-content: center; width: 100%; }} .web-hosting-90-off-image {max-width: 90%;} .content-wrapper {min-height: 454px; display: flex; flex-direction: column; justify-content: center; z-index: 5} .notice_content {display: flex; align-items: center;} * {-webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale;} .upgrade_button_red_sale{box-shadow: 0 2px 4px 0 rgba(255, 69, 70, 0.2); max-width: 350px; border: 0; border-radius: 3px; background-color: #ff4546 !important; padding: 15px 55px !important; font-family: 'Roboto', sans-serif; font-size: 16px; font-weight: 600; color: #ffffff;} .upgrade_button_red_sale:hover{color: #ffffff !important; background: #d10303 !important;}",style=document.createElement("style"),sheet=window.document.styleSheets[0];style.styleSheet?style.styleSheet.cssText=css:style.appendChild(document.createTextNode(css)),document.getElementsByTagName("head")[0].appendChild(style),document.getElementsByTagName("head")[0].appendChild(googleFont);var button=document.getElementsByClassName("upgrade_button_red")[0],link=button.parentElement;link.setAttribute("href","https://www.hostinger.com/hosting-starter-offer?utm_source=000webhost&utm_medium=panel&utm_campaign=000-wp"),link.innerHTML='<button class="upgrade_button_red_sale">Claim deal</button>',(notification=notification[0]).setAttribute("style","padding-bottom: 0; padding-top: 5px; background-color: #040713; background-size: cover; background-repeat: no-repeat; color: #ffffff; border-left-color: #040713;"),notification.className="notice notice-error is-dismissible";var mainContentHolder=document.getElementById("main_content");mainContentHolder.setAttribute("style","padding: 0;"),hostingerLogo[0].remove();var h1Tag=notification.getElementsByTagName("H1")[0];h1Tag.className="000-h1",h1Tag.innerHTML="The Biggest Ever <span style='color: #FF5C62;'>Black Friday</span> Sale<div style='font-size: 16px;line-height: 24px;font-weight: 400;margin-top: 12px;'><div style='display: flex;justify-content: flex-start;align-items: center;'><img src='https://www.000webhost.com/static/default.000webhost.com/images/generic/green-check-mark.png' alt='' style='margin-right: 10px; width: 20px;'>Managed WordPress Hosting</div><div style='display: flex;justify-content: flex-start;align-items: center;'><img src='https://www.000webhost.com/static/default.000webhost.com/images/generic/green-check-mark.png' alt='' style='margin-right: 10px; width: 20px;'>WordPress Acceleration</div><div style='display: flex;justify-content: flex-start;align-items: center;'><img src='https://www.000webhost.com/static/default.000webhost.com/images/generic/green-check-mark.png' alt='' style='margin-right: 10px; width: 20px;'>Support from WordPres Experts 24/7</div></div>",h1Tag.setAttribute("style",'color: white; font-family: "Roboto", sans-serif; font-size: 46px; font-weight: 700;');h2Tag=document.createElement("H2");h2Tag.innerHTML="<span style='font-size: 20px'>$</span>2.49<span style='font-size: 20px'>/mo</span>",h2Tag.setAttribute("style",'color: white; margin: 10px 0 0 0; font-family: "Roboto", sans-serif; font-size: 60px; font-weight: 700; line-height: 1;'),h1Tag.parentNode.insertBefore(h2Tag,h1Tag.nextSibling);var paragraph=notification.getElementsByTagName("p")[0];paragraph.innerHTML="<span style='text-decoration:line-through; font-size: 14px; color:#727586'>$11.99.mo</span><br>+ 2 Months Free",paragraph.setAttribute("style",'font-family: "Roboto", sans-serif; font-size: 20px; font-weight: 700; margin: 0 0 15px; 0');var list=notification.getElementsByTagName("UL")[0];list.remove();var org_html=mainContent.innerHTML,new_html='<div class="content-wrapper">'+mainContent.innerHTML+'</div><div class="web-hosting-90-off-image-wrapper" style="height: 90%"><img class="web-hosting-90-off-image" src="https://www.000webhost.com/static/default.000webhost.com/images/sales/bf2023/hero.png"></div>';mainContent.innerHTML=new_html;var saleImage=mainContent.getElementsByClassName("web-hosting-90-off-image")[0]}else if(null!=wordpressAdminBody&ification.length>0&&null!=mainContent){var bulletPoints = mainContent.getElementsByTagName('li');var replacement=['Increased performance (up to 5x faster) - Thanks to Hostinger’s WordPress Acceleration and Caching solutions','WordPress AI tools - Creating a new website has never been easier','Weekly or daily backups - Your data will always be safe','Fast and dedicated 24/7 support - Ready to help you','Migration of your current WordPress sites to Hostinger is automatic and free!','Try Premium Web Hosting now - starting from $1.99/mo'];for (var i=0;i<bulletPoints.length;i++){bulletPoints[i].innerHTML = replacement[i];}}</script></body>
</html>